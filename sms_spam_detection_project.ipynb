{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA02FzF3SPZ4"
   },
   "source": [
    "# **SMS Spam Detection Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Project Overview**\n",
    "\n",
    "The SMS Spam Detection project aims to build a machine learning model capable of classifying SMS messages as either spam or ham (legitimate). The dataset used for this project is the SMS Spam Collection, which consists of 5,574 SMS messages labeled accordingly. The goal is to develop a robust classifier that can help filter out unwanted spam messages automatically.\n",
    "\n",
    "# 2. **Dataset Description**\n",
    "\n",
    "**Source & Context**\n",
    "\n",
    "The dataset has been compiled from multiple sources, including:\n",
    "\n",
    "**Grumbletext Website** – A UK-based forum where users report SMS spam.\n",
    "\n",
    "**NUS SMS Corpus (NSC)** – A collection of 3,375 ham messages from Singaporean university students.\n",
    "\n",
    "**Caroline Tag’s PhD Thesis** – A collection of 450 ham messages.\n",
    "\n",
    "**SMS Spam Corpus v.0.1 Big** – Contains 1,002 ham and 322 spam messages.\n",
    "\n",
    "# Dataset Structure\n",
    "\n",
    "The dataset consists of two main columns:\n",
    "\n",
    "**v1 (Label)** – Indicates whether the message is ham (legitimate) or spam (unwanted message).\n",
    "\n",
    "**v2 (Message Text)** – The raw text content of the SMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZvlVH9uSK0Z"
   },
   "source": [
    "**Import Necessory Libaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "YHo_y6ZCRVSD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3YTpU-tSA3x"
   },
   "source": [
    "**Load DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0PKA9hiRVSK",
    "outputId": "9a923d68-da94-4e1e-b618-ff63698f70f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "# Size Of Dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOGHgOiATCZg"
   },
   "source": [
    "**Show Top 5 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SkVPfds_RVSL",
    "outputId": "18308e8f-3320-42f5-a623-fcec1cde24fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKpsa5okTFTf"
   },
   "source": [
    "**Rename Columns for readability and Take only Usefull Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6O_oVsLRVSM",
    "outputId": "231139fb-5c11-4fc6-932c-8fc97cb437c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename Columns name\n",
    "df.rename(columns={'v1': 'label', 'v2': 'text'}, inplace=True)\n",
    "# Take Only ?Usefull Columns\n",
    "df = df[[\"text\", \"label\"]]\n",
    "# Size of Of data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNTXUfABShWv"
   },
   "source": [
    "# **Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9WwhxCMSZgS"
   },
   "source": [
    "**Checke Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "OEpAoyGsRVSN",
    "outputId": "163ca101-7007-4bc2-8e70-fa7d26bf56ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe3WPHZ1Sdcx"
   },
   "source": [
    "**Chack Duplicated Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzNo5nSkRVSN",
    "outputId": "34bfc0ba-a376-4138-cf16-c067df28e452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dublicated Values is -->>  403\n",
      "\n",
      "Drop Succesfully Duplicates\n",
      "\n",
      "After Drop Dublicated Values is -->>  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Dublicated Values is -->> \",df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"\\nDrop Succesfully Duplicates\\n\")\n",
    "print(\"After Drop Dublicated Values is -->> \",df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHtMnKhdRVSO"
   },
   "source": [
    "# **Label**\n",
    "\n",
    "\n",
    "\n",
    "*   **Unbalanced DataSet**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "QFSzoTITRVSR",
    "outputId": "1d608204-5fae-48c2-ef57-3a658dde2726"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4516\n",
       "spam     653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAF6qJuXTkR3"
   },
   "source": [
    "# **Data Preprocessing**\n",
    "\n",
    "To ensure optimal performance of the classification model, the following preprocessing steps were applied:\n",
    "\n",
    "1. **Text Normalization**: Conversion to lowercase and removal of special characters.\n",
    "\n",
    "2.  **Tokenization:** Splitting messages into individual words.\n",
    "\n",
    "3. **Stopword Removal:** Removing common words that do not contribute to meaning.\n",
    "\n",
    "4. **Lemmatization/Stemming:** Reducing words to their root forms to improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "03xyE58hRVSS",
    "outputId": "f8f89aef-f5c7-4e15-f806-9c52a47b5db2"
   },
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "# Get stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Define the text preprocessing function\n",
    "def preprocessing_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabetic characters (keeps spaces)\n",
    "    tokens = word_tokenize(text)  # Tokenize text into words\n",
    "    tokens = [stemming.stem(token) for token in tokens if token not in stop_words]  # Stemmig and remove stopwords\n",
    "    text = \" \".join(tokens)  # Join tokens back to string\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "# Apply preprocessing to the 'text' column of the dataframe\n",
    "df[\"clean_text\"] = df[\"text\"].apply(preprocessing_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6PclfLxORVSS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "       Before Text Preprocessing      \n",
      "===================================\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "===================================\n",
      "       After Text Preprocessing      \n",
      "===================================\n",
      "go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n"
     ]
    }
   ],
   "source": [
    "print(\"===================================\")\n",
    "print(\"       Before Text Preprocessing      \")\n",
    "print(\"===================================\")\n",
    "\n",
    "print(df[\"text\"].iloc[0])\n",
    "\n",
    "print(\"===================================\")\n",
    "print(\"       After Text Preprocessing      \")\n",
    "print(\"===================================\")\n",
    "\n",
    "print(df[\"clean_text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jL8LmriUvY-"
   },
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE5kaSiGUQT3"
   },
   "source": [
    "**Split Data in two parts Dependent and Independent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kzd-wVv8RVST"
   },
   "outputs": [],
   "source": [
    "X=df[\"text\"]\n",
    "y=df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqAhN2RXUbN9"
   },
   "source": [
    "**Split Dataset into Tain and Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B6Tfuu-DRVSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4135,)\n",
      "x_test shape: (1034,)\n",
      "y_train shape: (4135,)\n",
      "y_test shape: (1034,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of train and test sets\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKype0dnUiaS"
   },
   "source": [
    "**Apply Label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QP-QUp9IRVSU"
   },
   "outputs": [],
   "source": [
    "encode = LabelEncoder()\n",
    "y_train = encode.fit_transform(y_train)\n",
    "y_test = encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVYmHx08VFat"
   },
   "source": [
    "# **Vectorization: Converting text data into numerical features using:**\n",
    "\n",
    "1. **Bag of Words (BoW)**\n",
    "\n",
    "2. **TF-IDF (Term Frequency-Inverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VV6x2-uFRVSV"
   },
   "source": [
    "# **Bag Of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VKQbyF_XRVSV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4135, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer(max_features=5000, binary=True)\n",
    "x_train_bow = bow.fit_transform(x_train)\n",
    "x_test_bow = bow.transform(x_test)\n",
    "x_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OKpPPcmRVSV"
   },
   "source": [
    "# **TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "zlhBQaLSRVSW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4135, 5000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVfshLuGRVSW"
   },
   "source": [
    "# **Model Trainning**\n",
    "\n",
    "## **Selected Models**\n",
    "\n",
    "Several machine learning models were evaluated for classification:\n",
    "\n",
    "1. Logistic Regression\n",
    "\n",
    "2. Multinomial Naïve Bayes\n",
    "\n",
    "3. Random Forest Classifier\n",
    "\n",
    "4. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "rABdCseBRVSY"
   },
   "outputs": [],
   "source": [
    "# Define your models\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(n_estimators=50,random_state=2),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "}\n",
    "\n",
    "# Initialize lists to store results\n",
    "model_names = []\n",
    "accuracy_scores_bow = []\n",
    "precision_scores_bow = []\n",
    "\n",
    "\n",
    "accuracy_scores_tfidf = []\n",
    "precision_scores_tfidf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26uxsyvjRVSY"
   },
   "source": [
    "# **Train Using BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "p45fhvvYRVSZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model -- >> logistic_regression\n",
      "\n",
      "Train Accuracy == 0.9961305925030229\n",
      "Test Accuracy \n",
      "== 0.9825918762088974\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3627\n",
      "           1       1.00      0.97      0.98       508\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       1.00      0.98      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       889\n",
      "           1       0.99      0.88      0.93       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.99      0.94      0.96      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [  16  492]]\n",
      "Test Confusion Matrix == \n",
      " [[888   1]\n",
      " [ 17 128]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> MultinomialNB\n",
      "\n",
      "Train Accuracy == 0.9915356711003628\n",
      "Test Accuracy \n",
      "== 0.988394584139265\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3627\n",
      "           1       0.97      0.96      0.97       508\n",
      "\n",
      "    accuracy                           0.99      4135\n",
      "   macro avg       0.98      0.98      0.98      4135\n",
      "weighted avg       0.99      0.99      0.99      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       889\n",
      "           1       1.00      0.92      0.96       145\n",
      "\n",
      "    accuracy                           0.99      1034\n",
      "   macro avg       0.99      0.96      0.98      1034\n",
      "weighted avg       0.99      0.99      0.99      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3613   14]\n",
      " [  21  487]]\n",
      "Test Confusion Matrix == \n",
      " [[889   0]\n",
      " [ 12 133]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> RandomForestClassifier\n",
      "\n",
      "Train Accuracy == 0.999758162031439\n",
      "Test Accuracy \n",
      "== 0.9787234042553191\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3627\n",
      "           1       1.00      1.00      1.00       508\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       1.00      1.00      1.00      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       889\n",
      "           1       0.99      0.86      0.92       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.93      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [   1  507]]\n",
      "Test Confusion Matrix == \n",
      " [[888   1]\n",
      " [ 21 124]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> XGBClassifier\n",
      "\n",
      "Train Accuracy == 0.9915356711003628\n",
      "Test Accuracy \n",
      "== 0.9825918762088974\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3627\n",
      "           1       1.00      0.94      0.96       508\n",
      "\n",
      "    accuracy                           0.99      4135\n",
      "   macro avg       0.99      0.97      0.98      4135\n",
      "weighted avg       0.99      0.99      0.99      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       889\n",
      "           1       0.98      0.90      0.94       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.95      0.96      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3625    2]\n",
      " [  33  475]]\n",
      "Test Confusion Matrix == \n",
      " [[886   3]\n",
      " [ 15 130]]\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Loop through models and evaluate them\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel -- >> {name}\\n\")\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train_bow, y_train)\n",
    "\n",
    "    # Predict on train and test data\n",
    "    train_pred_bow = model.predict(x_train_bow)\n",
    "    test_pred_bow = model.predict(x_test_bow)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    train_acc_score_bow = accuracy_score(y_train, train_pred_bow)\n",
    "    test_acc_score_bow = accuracy_score(y_test, test_pred_bow)\n",
    "\n",
    "    # Calculate precision scores\n",
    "    train_precision_score_bow = precision_score(y_train, train_pred_bow)\n",
    "    test_precision_score_bow = precision_score(y_test, test_pred_bow)\n",
    "\n",
    "    # Generate classification reports\n",
    "    train_class_rep_bow = classification_report(y_train, train_pred_bow)\n",
    "    test_class_rep_bow = classification_report(y_test, test_pred_bow)\n",
    "\n",
    "    # Generate confusion matrices\n",
    "    train_conf_matrix_bow = confusion_matrix(y_train, train_pred_bow)\n",
    "    test_conf_matrix_bow = confusion_matrix(y_test, test_pred_bow)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Train Accuracy == {train_acc_score_bow}\")\n",
    "    print(f\"Test Accuracy \\n== {test_acc_score_bow}\")\n",
    "\n",
    "    print(\"\\nTrain Classification Report \\n\", train_class_rep_bow)\n",
    "    print(\"\\nTest Classification Report \\n\", test_class_rep_bow)\n",
    "\n",
    "    print(\"Train Confusion Matrix == \\n\", train_conf_matrix_bow)\n",
    "    print(\"Test Confusion Matrix == \\n\", test_conf_matrix_bow)\n",
    "\n",
    "    print(\"==\"*20)\n",
    "    print(\"==\"*20)\n",
    "\n",
    "    # Append results to the lists\n",
    "    model_names.append(name)\n",
    "    accuracy_scores_bow.append(test_acc_score_bow)\n",
    "    precision_scores_bow.append(test_precision_score_bow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGCYcnihRVSa"
   },
   "source": [
    "# **Train Using Tfidf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1Pvdwr38RVSa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model -- >> logistic_regression\n",
      "\n",
      "Train Accuracy == 0.9729141475211608\n",
      "Test Accuracy \n",
      "== 0.9700193423597679\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3627\n",
      "           1       0.99      0.78      0.88       508\n",
      "\n",
      "    accuracy                           0.97      4135\n",
      "   macro avg       0.98      0.89      0.93      4135\n",
      "weighted avg       0.97      0.97      0.97      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       889\n",
      "           1       0.97      0.81      0.88       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.97      0.90      0.93      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3625    2]\n",
      " [ 110  398]]\n",
      "Test Confusion Matrix == \n",
      " [[886   3]\n",
      " [ 28 117]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> MultinomialNB\n",
      "\n",
      "Train Accuracy == 0.973881499395405\n",
      "Test Accuracy \n",
      "== 0.9680851063829787\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3627\n",
      "           1       1.00      0.79      0.88       508\n",
      "\n",
      "    accuracy                           0.97      4135\n",
      "   macro avg       0.99      0.89      0.93      4135\n",
      "weighted avg       0.97      0.97      0.97      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       889\n",
      "           1       1.00      0.77      0.87       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.98      0.89      0.93      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [ 108  400]]\n",
      "Test Confusion Matrix == \n",
      " [[889   0]\n",
      " [ 33 112]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> RandomForestClassifier\n",
      "\n",
      "Train Accuracy == 0.999758162031439\n",
      "Test Accuracy \n",
      "== 0.9748549323017408\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3627\n",
      "           1       1.00      1.00      1.00       508\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       1.00      1.00      1.00      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       889\n",
      "           1       0.99      0.83      0.90       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.98      0.91      0.94      1034\n",
      "weighted avg       0.98      0.97      0.97      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [   1  507]]\n",
      "Test Confusion Matrix == \n",
      " [[888   1]\n",
      " [ 25 120]]\n",
      "========================================\n",
      "========================================\n",
      "\n",
      "Model -- >> XGBClassifier\n",
      "\n",
      "Train Accuracy == 0.9970979443772672\n",
      "Test Accuracy \n",
      "== 0.97678916827853\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3627\n",
      "           1       1.00      0.98      0.99       508\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       1.00      0.99      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       889\n",
      "           1       0.98      0.85      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.92      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [  12  496]]\n",
      "Test Confusion Matrix == \n",
      " [[887   2]\n",
      " [ 22 123]]\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Loop through models and evaluate them\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel -- >> {name}\\n\")\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train_tfidf, y_train)\n",
    "\n",
    "    # Predict on train and test data\n",
    "    train_pred_tfidf = model.predict(x_train_tfidf)\n",
    "    test_pred_tfidf = model.predict(x_test_tfidf)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    train_acc_score_tfidf = accuracy_score(y_train, train_pred_tfidf)\n",
    "    test_acc_score_tfidf  = accuracy_score(y_test, test_pred_tfidf)\n",
    "\n",
    "    # Calculate precision scores\n",
    "    train_precision_score_tfidf = precision_score(y_train, train_pred_tfidf)\n",
    "    test_precision_score_tfidf = precision_score(y_test, test_pred_tfidf)\n",
    "\n",
    "    # Generate classification reports\n",
    "    train_class_rep_tfidf = classification_report(y_train, train_pred_tfidf)\n",
    "    test_class_rep_tfidf = classification_report(y_test, test_pred_tfidf)\n",
    "\n",
    "    # Generate confusion matrices\n",
    "    train_conf_matrix_tfidf = confusion_matrix(y_train, train_pred_tfidf)\n",
    "    test_conf_matrix_tfidf = confusion_matrix(y_test, test_pred_tfidf)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Train Accuracy == {train_acc_score_tfidf}\")\n",
    "    print(f\"Test Accuracy \\n== {test_acc_score_tfidf}\")\n",
    "\n",
    "    print(\"\\nTrain Classification Report \\n\", train_class_rep_tfidf)\n",
    "    print(\"\\nTest Classification Report \\n\", test_class_rep_tfidf)\n",
    "\n",
    "    print(\"Train Confusion Matrix == \\n\", train_conf_matrix_tfidf)\n",
    "    print(\"Test Confusion Matrix == \\n\", test_conf_matrix_tfidf)\n",
    "\n",
    "    print(\"==\"*20)\n",
    "    print(\"==\"*20)\n",
    "\n",
    "    # Append results to the lists\n",
    "    accuracy_scores_tfidf.append(test_acc_score_tfidf)\n",
    "    precision_scores_tfidf.append(test_precision_score_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7yw2tqFRVSb"
   },
   "source": [
    "**Store Result in DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "YmFAZ3AMRVSc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy_score_bow</th>\n",
       "      <th>Precision_score_bow</th>\n",
       "      <th>Accuracy_score_tfidf</th>\n",
       "      <th>Precision_score_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.982592</td>\n",
       "      <td>0.992248</td>\n",
       "      <td>0.970019</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.988395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.974855</td>\n",
       "      <td>0.991736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.982592</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Models  Accuracy_score_bow  Precision_score_bow  \\\n",
       "0     logistic_regression            0.982592             0.992248   \n",
       "1           MultinomialNB            0.988395             1.000000   \n",
       "2  RandomForestClassifier            0.978723             0.992000   \n",
       "3           XGBClassifier            0.982592             0.977444   \n",
       "\n",
       "   Accuracy_score_tfidf  Precision_score_tfidf  \n",
       "0              0.970019               0.975000  \n",
       "1              0.968085               1.000000  \n",
       "2              0.974855               0.991736  \n",
       "3              0.976789               0.984000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Models\": model_names,\n",
    "    \"Accuracy_score_bow\": accuracy_scores_bow,\n",
    "    \"Precision_score_bow\": precision_scores_bow,\n",
    "    \"Accuracy_score_tfidf\": accuracy_scores_tfidf,\n",
    "    \"Precision_score_tfidf\": precision_scores_tfidf\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Nt5x8DcRVSc"
   },
   "source": [
    "**Accuracy is Aleady Good So We donot need to do Hyper Parameter Tunning**\n",
    "\n",
    "* Best Model is -- >> **MultiNomialNB** with **BOW**\n",
    "  * With high **Accuracy and Precission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy == 0.9961305925030229\n",
      "Test Accuracy == 0.9825918762088974\n",
      "Train Precision Score == 0.9961475868812694\n",
      "Test Precision Score == 0.9827625933060309\n",
      "\n",
      "Train Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3627\n",
      "           1       1.00      0.97      0.98       508\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       1.00      0.98      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "\n",
      "Test Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       889\n",
      "           1       0.99      0.88      0.93       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.99      0.94      0.96      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "Train Confusion Matrix == \n",
      " [[3627    0]\n",
      " [  16  492]]\n",
      "Test Confusion Matrix == \n",
      " [[888   1]\n",
      " [ 17 128]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "log_reg.fit(x_train_bow, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "train_pred = log_reg.predict(x_train_bow)\n",
    "test_pred = log_reg.predict(x_test_bow)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_acc_score = accuracy_score(y_train, train_pred)\n",
    "test_acc_score = accuracy_score(y_test, test_pred)\n",
    "\n",
    "# Calculate precision scores\n",
    "train_precision_score = precision_score(y_train, train_pred, average='weighted')\n",
    "test_precision_score = precision_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "# Generate classification reports\n",
    "train_class_rep = classification_report(y_train, train_pred)\n",
    "test_class_rep = classification_report(y_test, test_pred)\n",
    "\n",
    "# Generate confusion matrices\n",
    "train_conf_matrix = confusion_matrix(y_train, train_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Train Accuracy == {train_acc_score}\")\n",
    "print(f\"Test Accuracy == {test_acc_score}\")\n",
    "\n",
    "# Print precision scores\n",
    "print(f\"Train Precision Score == {train_precision_score}\")\n",
    "print(f\"Test Precision Score == {test_precision_score}\")\n",
    "\n",
    "# Generate and print classification reports\n",
    "print(\"\\nTrain Classification Report \\n\", train_class_rep)\n",
    "print(\"\\nTest Classification Report \\n\", test_class_rep)\n",
    "\n",
    "# Print confusion matrices\n",
    "print(\"Train Confusion Matrix == \\n\", train_conf_matrix)\n",
    "print(\"Test Confusion Matrix == \\n\", test_conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "alOdcxlwRVSd"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model.pkl\",'wb') as file:\n",
    "    pickle.dump(log_reg, file)\n",
    "    \n",
    "with open(\"encode.pkl\",'wb') as file1:\n",
    "    pickle.dump(encode, file1)\n",
    "\n",
    "with open(\"BOW.pkl\",'wb') as file2:\n",
    "    pickle.dump(bow,file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 483,
     "sourceId": 982,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
